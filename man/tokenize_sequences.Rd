% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenize_sequences.R
\name{tokenize_sequences}
\alias{tokenize_sequences}
\title{Tokenize Biological Sequences Using BPE}
\usage{
tokenize_sequences(bioBPE_seqs, vocab_size = 15)
}
\arguments{
\item{bioBPE_seqs}{A \code{bioBPE_preprocessed} object containing preprocessed D
NA, RNA, or AA sequences.}

\item{vocab_size}{An integer specifying the maximum size of the learned BPE
vocabulary (default is 15).}
}
\value{
A list containing:
\describe{
\item{\code{vocab}}{The learned BPE vocabulary, including merges and base
tokens.}
\item{\code{tokens}}{A list of tokenized sequences, where each sequence is
a vector of token strings.}
}
}
\description{
Learns a byte-pair encoding (BPE) vocabulary from preprocessed sequences and
applies it to generate tokenized representations for downstream analysis.
}
\details{
The tokenization step includes learning the BPE vocabulary and
applying it to the sequences. The exact operations are delegated into
internal helper functions:
\itemize{
\item \code{.BioTokenizeR_apply_bpe()} to apply the learned vocabulary to
the sequences.
\item \code{.BioTokenizeR_learn_bpe_vocabulary} to learn the BPE vocabulary
\item \code{.BioTokenizeR_compute_bio_pair_frequencies} to compute
biology-aware token pair frequencies within the BPE algorithm
\item \code{.BioTokenizeR_merge_best_pair} to merge the best token pair
within the BPE algorithm
}
}
\examples{
\dontrun{
   # Generate simulated data
   data <- generate_data(
       n          = 3, 
       length     = 1000, 
       vocab_size = 25, 
       preprocess = TRUE,
       annotate   = TRUE,
       tokenize   = FALSE,
       summarize  = FALSE,
       verbose    = FALSE
   )
   
   # Tokenize the preprocessed and annotated sequences
   dna_tokens <- tokenize_sequences(bioBPE_seqs = data$dna_annot,
                                    vocab_size  = 15)
   rna_tokens <- tokenize_sequences(bioBPE_seqs = data$rna_annot,
                                    vocab_size  = 15)
   aa_tokens <- tokenize_sequences(bioBPE_seqs = data$aa_annot,
                                   vocab_size  = 15)
}

}
\seealso{
Other tokenization: 
\code{\link{.BioTokenizeR_apply_bpe}()},
\code{\link{.BioTokenizeR_compute_bio_pair_frequencies}()},
\code{\link{.BioTokenizeR_learn_bpe_vocabulary}()},
\code{\link{.BioTokenizeR_merge_best_pair}()}
}
\concept{tokenization}
\keyword{internal}
\keyword{tokenization}
