% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/analyze_tokens.R
\name{summarize_tokens}
\alias{summarize_tokens}
\title{Summarize Tokenized Biological Sequences}
\usage{
summarize_tokens(tokens)
}
\arguments{
\item{tokens}{A non-empty list of character vectors representing tokenized
sequences.}
}
\value{
An object of class \code{"bioBPE_summary"}, being a list containing:
\describe{
\item{\code{corpus}}{List of corpus-level statistics: number of sequences,
total tokens, average and median sequence lengths, and vocabulary
size.}
\item{\code{token_summary}}{Data frame with each token's frequency, length,
and GC-like flag.}
\item{\code{token_length_summary}}{Summary of token lengths.}
}
}
\description{
Computes summary statistics for a list of tokenized biological sequences,
including corpus-level metrics, token frequencies, token lengths, and
basic biological features (e.g., GC-like tokens).
}
\examples{
\dontrun{
   # Generate simulated data
   data <- generate_data(
       n          = 3, 
       length     = 1000, 
       vocab_size = 25, 
       preprocess = TRUE,
       annotate   = TRUE,
       tokenize   = TRUE,
       summarize  = FALSE,
       verbose    = FALSE
   )
   
   # Summarize the preprocessed, annotated, and tokenized sequences
   dna_summary <- summarize_tokens(tokens = data$dna_tokens$tokens)
   rna_summary <- summarize_tokens(tokens = data$rna_tokens$tokens)
   aa_summary <- summarize_tokens(tokens = data$aa_tokens$tokens)
}


}
\concept{summary}
\keyword{summary}
