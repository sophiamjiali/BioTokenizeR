% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenize_sequences.R
\name{.BioTokenizeR_learn_bpe_vocabulary}
\alias{.BioTokenizeR_learn_bpe_vocabulary}
\title{Learn Byte-Pair Encoding (BPE) Vocabulary from Biological Sequences}
\usage{
.BioTokenizeR_learn_bpe_vocabulary(bioBPE_seqs, vocab_size = 15)
}
\arguments{
\item{bioBPE_seqs}{A \code{bioBPE_preprocessed} object containing sequences and
annotation metadata.}

\item{vocab_size}{Integer specifying the desired maximum size of the learned
BPE vocabulary (default 15).}
}
\value{
A list containing:
\describe{
\item{vocab}{Character vector of all tokens in the learned BPE vocabulary.}
\item{merges}{List of integer pairs representing the merge operations
applied.}
\item{bio_scores}{Numeric vector of biological scores associated with each
sequence.}
}
}
\description{
Learns a BPE vocabulary from preprocessed biological sequences by
iteratively identifying the most frequent adjacent token pairs and merging
them into new tokens until the specified vocabulary size is reached.
The process is weighted by biological scores derived from sequence annotations.
}
\seealso{
Other tokenization: 
\code{\link{.BioTokenizeR_apply_bpe}()},
\code{\link{.BioTokenizeR_compute_bio_pair_frequencies}()},
\code{\link{.BioTokenizeR_merge_best_pair}()},
\code{\link{tokenize_sequences}()}
}
\concept{tokenization}
\keyword{internal}
\keyword{tokenization}
