% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenize_sequences.R
\name{.BioTokenizeR_apply_bpe}
\alias{.BioTokenizeR_apply_bpe}
\title{Apply Learned BPE Vocabulary to Sequences}
\usage{
.BioTokenizeR_apply_bpe(seqs, vocab)
}
\arguments{
\item{seqs}{A character vector of sequences to tokenize.}

\item{vocab}{A list returned by \code{.BioTokenizeR_learn_bpe_vocabulary}
containing base tokens and the learned merge operations.}
}
\value{
A list of tokenized sequences, where each element is a character
vector of tokens corresponding to a single sequence.
}
\description{
Converts sequences into tokenized form using a learned byte-pair encoding (BPE)
vocabulary. Base tokens are first converted to integer IDs, and learned merges
are applied sequentially to generate final tokenized sequences.
}
\references{
{
Medvedev A, Viswanathan K, Kanithi P (2025). BioToken and BioFM -
Biologicallyâ€‘Informed Tokenization Framework. bioRxiv.
https://doi.org/10.1101/2025.03.27.645711

R Core Team (2025). R: A Language and Environment for Statistical
Computing. R Foundation for Statistical Computing, Vienna, Austria.
https://www.R-project.org/.
}
}
\seealso{
Other tokenization: 
\code{\link{.BioTokenizeR_compute_bio_pair_frequencies}()},
\code{\link{.BioTokenizeR_learn_bpe_vocabulary}()},
\code{\link{.BioTokenizeR_merge_best_pair}()},
\code{\link{tokenize_sequences}()}
}
\concept{tokenization}
\keyword{internal}
\keyword{tokenization}
